{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import animation\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "#from osgeo import gdal\n",
    "import sklearn.preprocessing as sk\n",
    "#from __future__ import division\n",
    "import PIL\n",
    "import cv2\n",
    "from numpy.linalg import inv\n",
    "import os\n",
    "import random\n",
    "from fractal_generator import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulation optimize test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_contains(rect, point) :\n",
    "        if point[0] < rect[0] :\n",
    "            return False\n",
    "        elif point[1] < rect[1] :\n",
    "            return False\n",
    "        elif point[0] > rect[2] :\n",
    "            return False\n",
    "        elif point[1] > rect[3] :\n",
    "            return False\n",
    "        return True\n",
    "    \n",
    "def measure_triangle(image, points):\n",
    "    rect = (0, 0, image.shape[1], image.shape[0])\n",
    "    sub_div = cv2.Subdiv2D(rect)\n",
    "\n",
    "    for p in points:\n",
    "        print(p)\n",
    "        sub_div.insert(p)\n",
    "\n",
    "    triangle_list = sub_div.getTriangleList()\n",
    "\n",
    "    triangle = []\n",
    "    pt = []\n",
    "\n",
    "    for t in triangle_list:\n",
    "        pt.append((t[0], t[1]))\n",
    "        pt.append((t[2], t[3]))\n",
    "        pt.append((t[4], t[5]))\n",
    "\n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])\n",
    "\n",
    "        if rect_contains(rect, pt1) and rect_contains(rect, pt2) and rect_contains(rect, pt3):\n",
    "            ind = []\n",
    "            for j in range(0, 3):\n",
    "                for k in range(0, len(points)):\n",
    "                    if abs(pt[j][0] - points[k][0]) < 1.0 and abs(pt[j][1] - points[k][1]) < 1.0:\n",
    "                        ind.append(k)\n",
    "            if len(ind) == 3:\n",
    "                triangle.append((ind[0], ind[1], ind[2]))\n",
    "\n",
    "        pt = []\n",
    "\n",
    "    return triangle\n",
    "def apply_affine_transform(src, src_tri, target_tri, size):\n",
    "    warp_mat = cv2.getAffineTransform(np.float32(src_tri), np.float32(target_tri))\n",
    "    dst = cv2.warpAffine(src, warp_mat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR,\n",
    "                         borderMode=cv2.BORDER_REFLECT_101)\n",
    "    return dst\n",
    "\n",
    "\n",
    "def morph_triangle(img1, img2, img, t1, t2, t, alpha):\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "    r = cv2.boundingRect(np.float32([t]))\n",
    "    #print(r)\n",
    "    t1_rect = []\n",
    "    t2_rect = []\n",
    "    t_rect = []\n",
    "\n",
    "    for i in range(3):\n",
    "        t_rect.append(((t[i][0] - r[0]), (t[i][1] - r[1])))\n",
    "        t1_rect.append(((t1[i][0] - r1[0]), (t1[i][1] - r1[1])))\n",
    "        t2_rect.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
    "    #mask = np.zeros((r[3], r[2], 3), dtype=np.float32)\n",
    "    mask = np.zeros((r[3], r[2]), dtype=np.float32)\n",
    "    #print(plt.imshow(mask))\n",
    "    cv2.fillConvexPoly(mask, np.int32(t_rect), (1.0, 1.0, 1.0), 16, 0)\n",
    "\n",
    "    img1_rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "    img2_rect = img2[r2[1]:r2[1] + r2[3], r2[0]:r2[0] + r2[2]]\n",
    "    size = (r[2], r[3])\n",
    "\n",
    "    warp_image1 = apply_affine_transform(img1_rect, t1_rect, t_rect, size)\n",
    "    #print(warp_image1)\n",
    "    warp_image2 = apply_affine_transform(img2_rect, t2_rect, t_rect, size)\n",
    "    img_rect = (1.0 - alpha) * warp_image1 + alpha * warp_image2\n",
    "    #print(plt.imshow(warp_image1))\n",
    "    #print(0*(1 - mask) + img_rect * mask)\n",
    "    img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] = img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] * (1 - mask) + img_rect * mask\n",
    "    return img\n",
    "\n",
    "def get_morph(del_triangles, src_img, src_points, target_img, target_points, alpha = 0.5):\n",
    "\n",
    "    weighted_pts = []\n",
    "    for i in range(len(src_points)):\n",
    "        x = (1 - alpha) * src_points[i][0] + alpha * target_points[i][0]\n",
    "        y = (1 - alpha) * src_points[i][1] + alpha * target_points[i][1]\n",
    "        weighted_pts.append((x, y))\n",
    "    img_morph = np.zeros(src_img.shape, dtype=src_img.dtype)\n",
    "    \n",
    "    img_stack = []\n",
    "    for triangle in del_triangles:\n",
    "        x, y, z = triangle\n",
    "        t1 = [src_points[x], src_points[y], src_points[z]]\n",
    "        #print(t1)\n",
    "        t2 = [target_points[x], target_points[y], target_points[z]]\n",
    "        #print(t2)\n",
    "        t = [weighted_pts[x], weighted_pts[y], weighted_pts[z]]\n",
    "        #print(t)\n",
    "        img_stack.append(morph_triangle(src_img, target_img, img_morph, t1, t2, t, alpha))\n",
    "    return img_stack\n",
    "\n",
    "def contrast(image):\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image)):\n",
    "            if image[i][j] >= 0.5:\n",
    "                image[i][j] = 1\n",
    "            elif image[i][j] < 0.5:\n",
    "                image[i][j] = 0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(im_in)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delaunay_morphing (im_in, im_out, src_points=None, target_points=None, steps = 25):\n",
    "    im_in = (im_in - np.min(im_in))/np.ptp(im_in)\n",
    "    im_out = (im_out - np.min(im_out))/np.ptp(im_out)\n",
    "    if src_points == None:\n",
    "        src_points = [(0, 0), (0, len(im_in)-1), (len(im_in)-1, 0), (len(im_in)-1, len(im_in)-1), \n",
    "                      (len(im_in)/2, len(im_in)/3), (len(im_in)/4, len(im_in)/4)]\n",
    "    if target_points == None:\n",
    "        target_points = [(0, 0), (0, len(im_in)-1), (len(im_in)-1, 0), (len(im_in)-1, len(im_in)-1), \n",
    "                      (len(im_in)/3, len(im_in)/2), (len(im_in)/4, len(im_in)/4)]\n",
    "    avg_points = []\n",
    "    for i in range(len(src_points)):\n",
    "        x = 0.5 * src_points[i][0] + 0.5 * target_points[i][0]\n",
    "        y = 0.5 * src_points[i][1] + 0.5 * target_points[i][1]\n",
    "        avg_points.append((int(x), int(y)))\n",
    "        \n",
    "    print(avg_points)\n",
    "    triangles = measure_triangle(im_in, avg_points)\n",
    "    del_morph = []\n",
    "    for percent in np.linspace(0, 1, num=steps): \n",
    "        del_morph.append(get_morph(triangles, im_in, src_points, im_out, target_points, alpha=percent)[:][0]) ### multiples images are created in get_morph OPTIMIZATION TO BE DONE\n",
    "    return del_morph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (0, 1023),\n",
       " (1023, 0),\n",
       " (1023, 1023),\n",
       " (511, 341),\n",
       " (341, 511),\n",
       " (341, 255),\n",
       " (255, 341),\n",
       " (767, 204),\n",
       " (204, 767)]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = len(im_in)-1\n",
    "n_pts = 10\n",
    "ratios = [(0, 0), (0, 1), (1, 0), (1, 1), (1/2, 1/3), (1/3, 1/2), (1/3, 1/4), (1/4, 1/3), (3/4, 1/5), (1/5, 3/4)]\n",
    "\n",
    "n=0\n",
    "coord_in = []\n",
    "coord_out = []\n",
    "while n < n_pts:\n",
    "    coord_in.append((int(l*ratios[n][0]), int(l*ratios[n][1])))\n",
    "    coord_out.append((int(l*ratios[n][0]), int(l*ratios[n][1])))\n",
    "    n+=1\n",
    "coord_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers1 = 0.3\n",
    "pers2 = 0.5\n",
    "im_in = fractal_generator(pers1, 1024)\n",
    "im_out = fractal_generator(pers2, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0), (0, 1023), (1023, 0), (1023, 1023), (511, 341), (341, 511), (341, 255), (255, 341), (767, 204), (204, 767)]\n",
      "(0, 0)\n",
      "(0, 1023)\n",
      "(1023, 0)\n",
      "(1023, 1023)\n",
      "(511, 341)\n",
      "(341, 511)\n",
      "(341, 255)\n",
      "(255, 341)\n",
      "(767, 204)\n",
      "(204, 767)\n"
     ]
    }
   ],
   "source": [
    "del_tot = delaunay_morphing(im_in, im_out, coord_in, coord_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1c0a3b6aa48>"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(contrast(del_tot[15]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6220078468322754\n",
      "1.5179994106292725\n",
      "2.126533031463623\n",
      "2.030235767364502\n",
      "2.011507272720337\n",
      "2.1147961616516113\n",
      "2.3200008869171143\n",
      "2.149249315261841\n",
      "2.279254198074341\n",
      "2.04451584815979\n",
      "2.1192312240600586\n",
      "2.15700364112854\n",
      "2.0527195930480957\n",
      "2.0721096992492676\n",
      "2.053004741668701\n",
      "2.2627487182617188\n",
      "2.0882985591888428\n",
      "2.106245756149292\n",
      "2.0049970149993896\n",
      "2.1455957889556885\n",
      "2.151540517807007\n",
      "2.2302656173706055\n",
      "2.1564314365386963\n",
      "2.6566269397735596\n",
      "5.570417642593384\n"
     ]
    }
   ],
   "source": [
    "dpi=150\n",
    "import time\n",
    "del_morph_clean = []\n",
    "for i in range(len(del_tot)):\n",
    "    start = time.time()\n",
    "    del_morph_clean.append(contrast(del_tot[i]))\n",
    "    stop = time.time()\n",
    "    print(stop-start)\n",
    "    \n",
    "    im = cv2.normalize(del_morph_clean[i], None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    \n",
    "    im = Image.fromarray(im).convert('L')\n",
    "    im.save(\"Morphing/frac_morph2{}-{}-{}.png\".format(pers1, pers2, i), dpi=(dpi, dpi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "im = cv2.normalize(del_tot[0], None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    \n",
    "im = Image.fromarray(im).convert('L')\n",
    "    \n",
    "im.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = 150\n",
    "#del_morph = []\n",
    "del_morph_clean = []\n",
    "import time\n",
    "\n",
    "#for percent in np.linspace(0, 1, num=10): \n",
    "#    del_morph.append(get_morph(triangles, im_in, src_points, im_out, target_points, alpha=percent))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(del_morph)):\n",
    "    start = time.time()\n",
    "    del_morph_clean.append(contrast(del_morph[i]))\n",
    "    stop = time.time()\n",
    "    print(stop-start)\n",
    "    \n",
    "    im = cv2.normalize(del_morph_clean[i], None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    \n",
    "    im = Image.fromarray(im).convert('L')\n",
    "    \n",
    "    #im.show()\n",
    "         \n",
    "    #im.save(\"Morphing/frac_morph{}-{}-{}.png\".format(pers1, pers2, i), dpi=(dpi, dpi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pers1 = 0.4\n",
    "pers2 = 0.6\n",
    "im_in = fractal_generator(pers1, 1024)\n",
    "#im_in = contrast(im_in)\n",
    "im_in = (im_in - np.min(im_in))/np.ptp(im_in)\n",
    "#im_in = im_out\n",
    "#im_in = np.repeat(im_in[:, :, np.newaxis], 3, axis=2)\n",
    "im_out = fractal_generator(pers2, 1024)\n",
    "#im_out = contrast(im_out)\n",
    "im_out = (im_out - np.min(im_out))/np.ptp(im_out)\n",
    "#im_out = np.repeat(im_out[:, :, np.newaxis], 3, axis=2)\n",
    "#src_points = [(0, 0), (0, 1023), (1023, 0), (1023, 1023), (445, 330), (120, 150), (750, 900), (100, 200), (200, 300), (850, 900)]\n",
    "#target_points = [(0, 0), (0, 1023), (1023, 0), (1023, 1023), (645, 430), (420, 450), (950, 700), (250, 300), (350, 450), (150, 500)]\n",
    "src_points = [(0, 0), (0, 1023), (1023, 0), (1023, 1023), (745, 230), (320, 650)]\n",
    "target_points = [(0, 0), (0, 1023), (1023, 0), (1023, 1023), (345, 330), (220, 150)]\n",
    "avg_points = []\n",
    "for i in range(len(src_points)):\n",
    "    x = 0.5 * src_points[i][0] + 0.5 * target_points[i][0]\n",
    "    y = 0.5 * src_points[i][1] + 0.5 * target_points[i][1]\n",
    "    avg_points.append((int(x), int(y)))\n",
    "triangles= measure_triangle(im_in, avg_points)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Triangulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from delaunay_div_conq import *\n",
    "\n",
    "def apply_affine_transform(src, src_tri, target_tri, size):\n",
    "    warp_mat = cv2.getAffineTransform(np.float32(src_tri), np.float32(target_tri))\n",
    "    dst = cv2.warpAffine(src, warp_mat, (size[0], size[1]), None, flags=cv2.INTER_LINEAR,\n",
    "                         borderMode=cv2.BORDER_REFLECT_101)\n",
    "    return dst\n",
    "\n",
    "\n",
    "def morph_triangle(img1, img2, img, t1, t2, t, alpha):\n",
    "    r1 = cv2.boundingRect(np.float32([t1]))\n",
    "    r2 = cv2.boundingRect(np.float32([t2]))\n",
    "    r = cv2.boundingRect(np.float32([t]))\n",
    "    #print(r)\n",
    "    t1_rect = []\n",
    "    t2_rect = []\n",
    "    t_rect = []\n",
    "\n",
    "    for i in range(3):\n",
    "        t_rect.append(((t[i][0] - r[0]), (t[i][1] - r[1])))\n",
    "        t1_rect.append(((t1[i][0] - r1[0]), (t1[i][1] - r1[1])))\n",
    "        t2_rect.append(((t2[i][0] - r2[0]), (t2[i][1] - r2[1])))\n",
    "    mask = np.zeros((r[3], r[2], 3), dtype=np.float32)\n",
    "    #mask = np.zeros((r[3], r[2]), dtype=np.float32)\n",
    "    #print(plt.imshow(mask))\n",
    "    cv2.fillConvexPoly(mask, np.int32(t_rect), (1.0, 1.0, 1.0), 16, 0)\n",
    "\n",
    "    img1_rect = img1[r1[1]:r1[1] + r1[3], r1[0]:r1[0] + r1[2]]\n",
    "    img2_rect = img2[r2[1]:r2[1] + r2[3], r2[0]:r2[0] + r2[2]]\n",
    "    size = (r[2], r[3])\n",
    "\n",
    "    warp_image1 = apply_affine_transform(img1_rect, t1_rect, t_rect, size)\n",
    "    #print(warp_image1)\n",
    "    warp_image2 = apply_affine_transform(img2_rect, t2_rect, t_rect, size)\n",
    "    img_rect = (1.0 - alpha) * warp_image1 + alpha * warp_image2\n",
    "    #print(plt.imshow(warp_image1))\n",
    "    #print(0*(1 - mask) + img_rect * mask)\n",
    "    img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] = img[r[1]:r[1]+r[3], r[0]:r[0]+r[2]] * (1 - mask) + img_rect * mask\n",
    "    return img\n",
    "\n",
    "def get_morph(del_triangles, src_img, src_points, target_img, target_points, alpha = 0.5):\n",
    "\n",
    "    weighted_pts = []\n",
    "    for i in range(len(src_points)):\n",
    "        x = (1 - alpha) * src_points[i][0] + alpha * target_points[i][0]\n",
    "        y = (1 - alpha) * src_points[i][1] + alpha * target_points[i][1]\n",
    "        weighted_pts.append((x, y))\n",
    "    img_morph = np.zeros(src_img.shape, dtype=src_img.dtype)\n",
    "    \n",
    "    img_stack = []\n",
    "    for triangle in del_triangles:\n",
    "        x, y, z = triangle\n",
    "        t1 = [src_points[x], src_points[y], src_points[z]]\n",
    "        #print(t1)\n",
    "        t2 = [target_points[x], target_points[y], target_points[z]]\n",
    "        #print(t2)\n",
    "        t = [weighted_pts[x], weighted_pts[y], weighted_pts[z]]\n",
    "        #print(t)\n",
    "        img_stack.append(morph_triangle(src_img, target_img, img_morph, t1, t2, t, alpha))\n",
    "    return img_stack\n",
    "    #return cv2.cvtColor(np.uint8(img_morph), cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "\n",
    "factor = 1.5 #increase contrast\n",
    "im_output = enhancer.enhance(factor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "pers1 = 0.6\n",
    "pers2 = 0.8\n",
    "im_in = fractal_generator(pers1, 1024)\n",
    "#im_in = contrast(im_in)\n",
    "im_in = (im_in - np.min(im_in))/np.ptp(im_in)\n",
    "im_in = np.repeat(im_in[:, :, np.newaxis], 3, axis=2)\n",
    "im_out = fractal_generator(pers2, 1024)\n",
    "#im_out = contrast(im_out)\n",
    "im_out = (im_out - np.min(im_out))/np.ptp(im_out)\n",
    "im_out = np.repeat(im_out[:, :, np.newaxis], 3, axis=2)\n",
    "#src_points = [(0, 0), (0, 511), (511, 0), (511, 511), (245, 130), (120, 150), (80, 23), (235, 345), (444, 333), (356, 234), (50, 222)]\n",
    "#target_points = [(0, 0), (0, 511), (511, 0), (511, 511), (345, 230), (220, 250), (180, 123), (335, 445), (444, 333), (356, 234), (50, 222) ]\n",
    "src_points = [(0, 0), (0, 1023), (1023, 0), (1023, 1023), (445, 330), (120, 150)]\n",
    "target_points = [(0, 0), (0, 1023), (1023, 0), (1023, 1023), (645, 430), (420, 450)]\n",
    "avg_points = []\n",
    "for i in range(len(src_points)):\n",
    "    x = 0.5 * src_points[i][0] + 0.5 * target_points[i][0]\n",
    "    y = 0.5 * src_points[i][1] + 0.5 * target_points[i][1]\n",
    "    avg_points.append((int(x), int(y)))\n",
    "\n",
    "start = time.time()\n",
    "triangles= measure_triangle(im_in, avg_points)\n",
    "stop = time.time()\n",
    "duration = (stop-start)\n",
    "\n",
    "#(0, 0), (0, 511), (511, 0), (511, 511)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dpi = 150\n",
    "del_morph = []\n",
    "del_morph_clean = []\n",
    "import time\n",
    "for percent in np.linspace(1, 0, num=20):\n",
    "    start = time.time()\n",
    "    del_morph.append(get_morph(triangles, im_in, src_points, im_out, target_points, alpha=percent))\n",
    "    stop = time.time()\n",
    "    print(stop-start)\n",
    "duration = stop-start\n",
    "for i in range(len(del_morph)):\n",
    "    del_morph_clean.append(contrast(del_morph[i][0][:, :, 0]))\n",
    "    im = cv2.normalize(del_morph_clean[i], None, alpha = 0, beta = 255, norm_type = cv2.NORM_MINMAX, dtype = cv2.CV_32F)\n",
    "    im = Image.fromarray(im).convert('L')\n",
    "    #im.show()\n",
    "         \n",
    "    im.save(\"Morphing/frac_morph{}-{}-{}.png\".format(pers1, pers2, i), dpi=(dpi, dpi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((del_morph_clean[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast(image):\n",
    "    for i in range(len(image)):\n",
    "        for j in range(len(image)):\n",
    "            if image[i][j] >= 0.5:\n",
    "                image[i][j] = 1\n",
    "            elif image[i][j] < 0.5:\n",
    "                image[i][j] = 0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from vid_lib import Video\n",
    "#video = Video('fractal_morph.avi', 20, 600, 800)\n",
    "#for percent in np.linspace(1, 0, num=200):\n",
    "#    print ('Writing Frame', 200 - int(percent*200) + 1)\n",
    "#    video.write(get_morph(alpha=percent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delaunay option2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(src_img, src_points, dst_img, dst_points): \n",
    "    \"\"\"Transforms source image to target image, overwriting the target image.\n",
    "    \"\"\"\n",
    "    for indices in get_triangulation_indices(src_points):\n",
    "        # Get triangles from indices\n",
    "        src_triangle = src_points[indices]\n",
    "        dst_triangle = dst_points[indices]\n",
    "\n",
    "        # Crop to triangle, to make calculations more efficient\n",
    "        src_triangle_cropped, src_img_cropped = crop_to_triangle(src_img, src_triangle)\n",
    "        dst_triangle_cropped, dst_img_cropped = crop_to_triangle(dst_img, dst_triangle)\n",
    "\n",
    "        # Calculate transfrom to warp from old image to new\n",
    "        transform = cv2.getAffineTransform(np.float32(src_triangle_cropped), np.float32(dst_triangle_cropped))\n",
    "\n",
    "        # Warp image\n",
    "        dst_img_warped = cv2.warpAffine(src_img_cropped, transform, (dst_img_cropped.shape[1], dst_img_cropped.shape[0]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101 )\n",
    "\n",
    "        # Create mask for the triangle we want to transform\n",
    "        mask = np.zeros(dst_img_cropped.shape, dtype = np.uint8)\n",
    "        cv2.fillConvexPoly(mask, np.int32(dst_triangle_cropped), (1.0, 1.0, 1.0), 16, 0);\n",
    "\n",
    "        # Delete all existing pixels at given mask\n",
    "        dst_img_cropped*=1-mask\n",
    "        # Add new pixels to masked area\n",
    "        dst_img_cropped+=dst_img_warped*mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def get_triangulation_indices(points):\n",
    "    \"\"\"Get indices triples for every triangle\n",
    "    \"\"\"\n",
    "    # Bounding rectangle\n",
    "    bounding_rect = (*points.min(axis=0), *points.max(axis=0))\n",
    "\n",
    "    # Triangulate all points\n",
    "    subdiv = cv2.Subdiv2D(bounding_rect)\n",
    "    subdiv.insert(list(points))\n",
    "\n",
    "    # Iterate over all triangles\n",
    "    for x1, y1, x2, y2, x3, y3 in subdiv.getTriangleList():\n",
    "        # Get index of all points\n",
    "        yield [(points==point).all(axis=1).nonzero()[0][0] for point in [(x1,y1), (x2,y2), (x3,y3)]]\n",
    "\n",
    "def crop_to_triangle(img, triangle):\n",
    "    \"\"\"Crop image to triangle\n",
    "    \"\"\"\n",
    "    # Get bounding rectangle\n",
    "    bounding_rect = cv2.boundingRect(triangle)\n",
    "\n",
    "    # Crop image to bounding box\n",
    "    img_cropped = img[bounding_rect[1]:bounding_rect[1] + bounding_rect[3],\n",
    "                      bounding_rect[0]:bounding_rect[0] + bounding_rect[2]]\n",
    "    # Move triangle to coordinates in cropped image\n",
    "    triangle_cropped = [(point[0]-bounding_rect[0], point[1]-bounding_rect[1]) for point in triangle]\n",
    "    return triangle_cropped, img_cropped\n",
    "\n",
    "def transform(src_img, src_points, dst_img, dst_points): \n",
    "    \"\"\"Transforms source image to target image, overwriting the target image.\n",
    "    \"\"\"\n",
    "    for indices in get_triangulation_indices(src_points):\n",
    "        # Get triangles from indices\n",
    "        src_triangle = src_points[indices]\n",
    "        dst_triangle = dst_points[indices]\n",
    "\n",
    "        # Crop to triangle, to make calculations more efficient\n",
    "        src_triangle_cropped, src_img_cropped = crop_to_triangle(src_img, src_triangle)\n",
    "        dst_triangle_cropped, dst_img_cropped = crop_to_triangle(dst_img, dst_triangle)\n",
    "\n",
    "        # Calculate transfrom to warp from old image to new\n",
    "        transform = cv2.getAffineTransform(np.float32(src_triangle_cropped), np.float32(dst_triangle_cropped))\n",
    "\n",
    "        # Warp image\n",
    "        dst_img_warped = cv2.warpAffine(src_img_cropped, transform, (dst_img_cropped.shape[1], dst_img_cropped.shape[0]), None, flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT_101 )\n",
    "\n",
    "        # Create mask for the triangle we want to transform\n",
    "        mask = np.zeros(dst_img_cropped.shape, dtype = np.uint8)\n",
    "        cv2.fillConvexPoly(mask, np.int32(dst_triangle_cropped), (1.0, 1.0, 1.0), 16, 0);\n",
    "\n",
    "        # Delete all existing pixels at given mask\n",
    "        dst_img_cropped*=1-mask\n",
    "        # Add new pixels to masked area\n",
    "        dst_img_cropped+=dst_img_warped*mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Looks in Python 2\n",
    "\n",
    "img = cv2.imread('frac1.jpeg')\n",
    "\n",
    "size = img.shape\n",
    "\n",
    "rect = (0, 0, size[1], size[0])\n",
    "\n",
    "subdiv  = cv2.Subdiv2D(rect);\n",
    "\n",
    "# Check if a point is inside a rectangle\n",
    "def rect_contains(rect, point) :\n",
    "    if point[0] < rect[0] :\n",
    "        return False\n",
    "    elif point[1] < rect[1] :\n",
    "        return False\n",
    "    elif point[0] > rect[2] :\n",
    "        return False\n",
    "    elif point[1] > rect[3] :\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Draw a point\n",
    "def draw_point(img, p, color ) :\n",
    "    cv2.circle( img, p, 2, color, cv2.LINE_AA)\n",
    "\n",
    "\n",
    "# Draw delaunay triangles\n",
    "def draw_delaunay(img, subdiv, delaunay_color ) :\n",
    "\n",
    "    triangleList = subdiv.getTriangleList();\n",
    "    size = img.shape\n",
    "    r = (0, 0, size[1], size[0])\n",
    "\n",
    "    for t in triangleList :\n",
    "        \n",
    "        pt1 = (t[0], t[1])\n",
    "        pt2 = (t[2], t[3])\n",
    "        pt3 = (t[4], t[5])\n",
    "        \n",
    "        if rect_contains(r, pt1) and rect_contains(r, pt2) and rect_contains(r, pt3) :\n",
    "        \n",
    "            cv2.line(img, pt1, pt2, delaunay_color, 1, cv2.LINE_AA, 0)\n",
    "            cv2.line(img, pt2, pt3, delaunay_color, 1, cv2.LINE_AA, 0)\n",
    "            cv2.line(img, pt3, pt1, delaunay_color, 1, cv2.LINE_AA, 0)\n",
    "\n",
    "\n",
    "# Draw voronoi diagram\n",
    "def draw_voronoi(img, subdiv) :\n",
    "\n",
    "    ( facets, centers) = subdiv.getVoronoiFacetList([])\n",
    "\n",
    "    for i in range(0,len(facets)) :\n",
    "        ifacet_arr = []\n",
    "        for f in facets[i] :\n",
    "            ifacet_arr.append(f)\n",
    "        \n",
    "        ifacet = np.array(ifacet_arr, np.int)\n",
    "        color = (random.randint(0, 255), random.randint(0, 255), random.randint(0, 255))\n",
    "\n",
    "        cv2.fillConvexPoly(img, ifacet, color, cv2.LINE_AA, 0);\n",
    "        ifacets = np.array([ifacet])\n",
    "        cv2.polylines(img, ifacets, True, (0, 0, 0), 1, cv2.LINE_AA, 0)\n",
    "        cv2.circle(img, (centers[i][0], centers[i][1]), 3, (0, 0, 0), cv2.LINE_AA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define window names\n",
    "win_delaunay = \"Delaunay Triangulation\"\n",
    "win_voronoi = \"Voronoi Diagram\"\n",
    "\n",
    "# Turn on animation while drawing triangles\n",
    "animate = True\n",
    "\n",
    "# Define colors for drawing.\n",
    "delaunay_color = (255,255,255)\n",
    "points_color = (0, 0, 255)\n",
    "\n",
    "# Read in the image.\n",
    "img = cv2.imread(\"frac2.jpeg\");\n",
    "\n",
    "# Keep a copy around\n",
    "img_orig = img.copy();\n",
    "\n",
    "# Rectangle to be used with Subdiv2D\n",
    "size = img.shape\n",
    "rect = (0, 0, size[1], size[0])\n",
    "\n",
    "# Create an instance of Subdiv2D\n",
    "subdiv = cv2.Subdiv2D(rect);\n",
    "\n",
    "# Create an array of points.\n",
    "points = [];\n",
    "\n",
    "# Read in the points from a text file\n",
    "with open(\"points.txt\") as file :\n",
    "    for line in file :\n",
    "        x, y = line.split()\n",
    "        points.append((int(x), int(y)))\n",
    "\n",
    "# Insert points into subdiv\n",
    "for p in points :\n",
    "    subdiv.insert(p)\n",
    "\n",
    "    # Show animation\n",
    "    if animate :\n",
    "        img_copy = img_orig.copy()\n",
    "        # Draw delaunay triangles\n",
    "        draw_delaunay( img_copy, subdiv, (255, 255, 255) );\n",
    "        cv2.imshow(win_delaunay, img_copy)\n",
    "        cv2.waitKey(100)\n",
    "\n",
    "# Draw delaunay triangles\n",
    "draw_delaunay( img, subdiv, (255, 255, 255) );\n",
    "\n",
    "# Draw points\n",
    "for p in points :\n",
    "    draw_point(img, p, (0,0,255))\n",
    "\n",
    "# Allocate space for Voronoi Diagram\n",
    "img_voronoi = np.zeros(img.shape, dtype = img.dtype)\n",
    "\n",
    "# Draw Voronoi diagram\n",
    "draw_voronoi(img_voronoi,subdiv)\n",
    "\n",
    "# Show results\n",
    "cv2.imshow(win_delaunay,img)\n",
    "cv2.imshow(win_voronoi,img_voronoi)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## PYTHON 2 AGAIN\n",
    "\n",
    "# Kuriakose Sony Theakanath\n",
    "# Face Morphing\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import argparse\n",
    "from pylab import arange, plot, sin, ginput, show\n",
    "import sys\n",
    "sys.path.append('/usr/local/lib/python2.7/site-packages')\n",
    "import cv2\n",
    "\n",
    "\n",
    "def writeGif(filename, images, duration=0.1, repeat=True, dither=False,\n",
    "                nq=0, subRectangles=True, dispose=None):\n",
    "    \"\"\" writeGif(filename, images, duration=0.1, repeat=True, dither=False,\n",
    "                    nq=0, subRectangles=True, dispose=None)\n",
    "\n",
    "    Write an animated gif from the specified images.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename : string\n",
    "        The name of the file to write the image to.\n",
    "    images : list\n",
    "        Should be a list consisting of PIL images or numpy arrays.\n",
    "        The latter should be between 0 and 255 for integer types, and\n",
    "        between 0 and 1 for float types.\n",
    "    duration : scalar or list of scalars\n",
    "        The duration for all frames, or (if a list) for each frame.\n",
    "    repeat : bool or integer\n",
    "        The amount of loops. If True, loops infinitetely.\n",
    "    dither : bool\n",
    "        Whether to apply dithering\n",
    "    nq : integer\n",
    "        If nonzero, applies the NeuQuant quantization algorithm to create\n",
    "        the color palette. This algorithm is superior, but slower than\n",
    "        the standard PIL algorithm. The value of nq is the quality\n",
    "        parameter. 1 represents the best quality. 10 is in general a\n",
    "        good tradeoff between quality and speed. When using this option,\n",
    "        better results are usually obtained when subRectangles is False.\n",
    "    subRectangles : False, True, or a list of 2-element tuples\n",
    "        Whether to use sub-rectangles. If True, the minimal rectangle that\n",
    "        is required to update each frame is automatically detected. This\n",
    "        can give significant reductions in file size, particularly if only\n",
    "        a part of the image changes. One can also give a list of x-y\n",
    "        coordinates if you want to do the cropping yourself. The default\n",
    "        is True.\n",
    "    dispose : int\n",
    "        How to dispose each frame. 1 means that each frame is to be left\n",
    "        in place. 2 means the background color should be restored after\n",
    "        each frame. 3 means the decoder should restore the previous frame.\n",
    "        If subRectangles==False, the default is 2, otherwise it is 1.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Check PIL\n",
    "    if PIL is None:\n",
    "        raise RuntimeError(\"Need PIL to write animated gif files.\")\n",
    "\n",
    "    # Check images\n",
    "    images = checkImages(images)\n",
    "\n",
    "    # Instantiate writer object\n",
    "    gifWriter = GifWriter()\n",
    "\n",
    "    # Check loops\n",
    "    if repeat is False:\n",
    "        loops = 1\n",
    "    elif repeat is True:\n",
    "        loops = 0 # zero means infinite\n",
    "    else:\n",
    "        loops = int(repeat)\n",
    "\n",
    "    # Check duration\n",
    "    if hasattr(duration, '__len__'):\n",
    "        if len(duration) == len(images):\n",
    "            duration = [d for d in duration]\n",
    "        else:\n",
    "            raise ValueError(\"len(duration) doesn't match amount of images.\")\n",
    "    else:\n",
    "        duration = [duration for im in images]\n",
    "\n",
    "    # Check subrectangles\n",
    "    if subRectangles:\n",
    "        images, xy = gifWriter.handleSubRectangles(images, subRectangles)\n",
    "        defaultDispose = 1 # Leave image in place\n",
    "    else:\n",
    "        # Normal mode\n",
    "        xy = [(0,0) for im in images]\n",
    "        defaultDispose = 2 # Restore to background color.\n",
    "\n",
    "    # Check dispose\n",
    "    if dispose is None:\n",
    "        dispose = defaultDispose\n",
    "    if hasattr(dispose, '__len__'):\n",
    "        if len(dispose) != len(images):\n",
    "            raise ValueError(\"len(xy) doesn't match amount of images.\")\n",
    "    else:\n",
    "        dispose = [dispose for im in images]\n",
    "\n",
    "\n",
    "    # Make images in a format that we can write easy\n",
    "    images = gifWriter.convertImagesToPIL(images, dither, nq)\n",
    "\n",
    "    # Write\n",
    "    fp = open(filename, 'wb')\n",
    "    try:\n",
    "        gifWriter.writeGifToFile(fp, images, duration, loops, xy, dispose)\n",
    "    finally:\n",
    "        fp.close()\n",
    "\n",
    "RATIO = 0.047619047619047616 # total of 20 frames\n",
    "TOTAL_FEATURE = 4 # 66 total feature points\n",
    "#TRIANGLES = [[20,21,23],[21,22,23],[0,1,36],[15,16,45],[0,17,36],[16,26,45],[17,18,37],[25,26,44],[17,36,37],[26,44,45],[18,19,38],[24,25,43],[18,37,38],[25,43,44],[19,20,38],[23,24,43],[20,21,39],[22,23,42],[20,38,39],[23,42,43],[21,22,27],[21,27,39],[22,27,42],[27,28,42],[27,28,39],[28,42,47],[28,39,40],[1,36,41],[15,45,46],[1,2,41],[14,15,46],[28,29,40],[28,29,47],[2,40,41],[14,46,47],[2,29,40],[14,29,47],[2,3,29],[13,14,29],[29,30,31],[29,30,35],[3,29,31],[13,29,35],[30,32,33],[30,33,34],[30,31,32],[30,34,35],[3,4,31],[12,13,35],[4,5,48],[11,12,54],[5,6,48],[10,11,54],[6,48,59],[10,54,55],[6,7,59],[9,10,55],[7,58,59],[9,55,56],[8,57,58],[8,56,57],[7,8,58],[8,9,56],[4,31,48],[12,35,54],[31,48,49],[35,53,54],[31,49,50],[35,52,53],[31,32,50],[34,35,52],[32,33,50],[33,34,52],[33,50,51],[33,51,52],[48,49,60],[49,60,50],[50,60,61],[50,51,61],[51,52,61],[61,62,52],[52,53,62],[53,54,62],[54,55,63],[55,56,63],[56,63,64],[56,57,64],[64,65,57],[57,58,65],[58,59,65],[48,59,65],[66,19,18],[66,18,17],[66,17,0],[67,66,0],[67,0,1],[67,1,2],[67,2,3],[67,3,68],[68,3,4],[68,4,5],[68,5,6],[68,6,7],[68,7,69],[69,7,8],[69,8,9],[69,9,70],[70,9,10],[70,10,11],[70,11,12],[70,12,13],[70,13,71],[71,13,14],[71,14,15],[71,15,16],[71,16,72],[72,16,26],[72,26,25],[72,25,24],[73,24,72],[73,23,24],[73,20,23],[73,19,20],[73,19,66], [60,65,61],[61,65,64],[61,64,62],[64,62,63],[36,37,41],[37,41,38],[41,38,40],[38,40,39],[42,43,47],[43,47,44],[44,47,46],[44,46,45],[48,60,65],[62,63,54]]\n",
    "TRIANGLES = [[1, 3, 2], [0, 2, 1], [0, 1, 3]]\n",
    "CORNERS = [(0, 0), (0, 512), (0, 512), (512, 512), (512, 512), (512, 512), (512, 0), (512, 0)] # adjust according to picture size\n",
    "\n",
    "# Part 1 - Allows user to select points on the supplied image.\n",
    "def selectPoints(im1_path, im2_path):\n",
    "\tim = im1_path\n",
    "\tplt.imshow(im)\n",
    "\tcounter, f_points = TOTAL_FEATURE, []\n",
    "\tx = [[128, 76, 34, 345], [26, 57, 83, 179]]\n",
    "\twhile counter != 0:\n",
    "\t\t#print (\"Click on screen!\")\n",
    "\t\t#x = ginput(1)\n",
    "\t\t\n",
    "\t\tcounter -= 1\n",
    "\t\tf_points.append([x[0][0], x[0][1]])\n",
    "\t\tplt.scatter(x[0][0], x[0][1])\n",
    "\t\tplt.draw()\n",
    "\t\tprint(\"Clicked point at \", x, \" | Clicks left: \", counter)\n",
    "\tplt.show()\n",
    "\tsecond_points = drag_control_points(im2_path, np.array(f_points))\n",
    "\tprint('hello')\n",
    "\tintermediate_feature = interpolatePts(combinePoints(f_points, second_points))\n",
    "\tframes = combineImages(intermediate_feature, TRIANGLES, im1_path, im2_path)\n",
    "\tframes.extend(frames[::-1])\n",
    "\t# otherone = [cv2.cvtColor(items, cv2.COLOR_RGB2BGR) for items in frames]\n",
    "\t# writeGif(\"lol.GIF\", otherone, duration=0.07)\n",
    "\twhile True:\n",
    "\t\tfor i in range (0, len(frames)): \n",
    "\t\t\tf = frames[i]\n",
    "\t\t\tcv2.waitKey(20) \n",
    "\t\t\tcv2.imshow(\"Cameras\",f) \n",
    "\t\t\tcv2.waitKey(20)\n",
    "\n",
    "# Step 2 - Creates a triangulation from the points given\n",
    "def interpolatePts(features):\n",
    "\tframe, middle = [(RATIO * i) for i in range(0, 22)], []\n",
    "\tfor r in range(0, len(frame)):\n",
    "\t\tmiddle.append([(pair[0][0] * (1 - frame[r]) + pair[1][0] * frame[r], pair[0][1] * (1-frame[r]) + pair[1][1] * frame[r]) for pair in features] + CORNERS)\n",
    "\treturn middle\n",
    "\n",
    "# Step 3, takes the features and warps it according to the triangles.\n",
    "def warpImage(orig, features, diang, src):\n",
    "\timage = src\n",
    "\tmasked_image = np.zeros(image.shape, dtype=np.uint8)\n",
    "\tfor t in diang:\n",
    "\t\tmask = np.zeros(image.shape, dtype=np.uint8)\n",
    "\t\tcv2.fillPoly(mask, np.array([[features[t[0]], features[t[1]], features[t[2]]]], dtype=np.int32), (255, 255, 255))\n",
    "\t\tmasked_image = cv2.bitwise_or(masked_image, cv2.bitwise_and(cv2.warpAffine(image, cv2.getAffineTransform(np.float32([orig[t[0]], orig[t[1]], orig[t[2]]]), np.float32([features[t[0]], features[t[1]], features[t[2]]])), (image.shape[1],image.shape[0])), mask))\n",
    "\treturn masked_image\n",
    "\n",
    "# Step 4, takes the warped images, and warps it, creating a video frame for viewing.\n",
    "def combineImages(features, diag, path1, path2):\n",
    "\tframes = []\n",
    "\tfor i in range(0, 22):\n",
    "\t\tframes.append(cv2.addWeighted(warpImage(features[0], features[i], diag, path1), 1 - RATIO * i, warpImage(features[21], features[i], diag, path2), RATIO * i, 0))\n",
    "\treturn frames\n",
    "\n",
    "# Sub-process - calculates the average face with a provided folder\n",
    "def averageFace(path):\n",
    "\tTOTAL_NUM = 100\n",
    "\tw, h, arr = Image.open(path + \"/1a.jpg\").size, np.zeros((h,w,3),np.float)\n",
    "\twhile TOTAL_NUM != 0:\n",
    "\t\tarr = arr + np.array(Image.open(path + \"/\" + str(TOTAL_NUM) + \"a.jpg\"), dtype=np.float) / 100\n",
    "\t\tTOTAL_NUM -= 1\n",
    "\tarr = np.array(np.round(arr), dtype=np.uint8)\n",
    "\tImage.fromarray(arr, mode=\"RGB\").save(\"average_ \" + path + \".jpeg\")\n",
    "\n",
    "# Sub-process - takes an image, allows a user to select points, and exports to .dat file\n",
    "def exportShape(path):\n",
    "\tplt.imshow(Image.open(path))\n",
    "\tcounter, f_points = TOTAL_FEATURE, []\n",
    "\twhile counter != 0:\n",
    "\t\tprint (\"Click on screen!\")\n",
    "\t\tx = ginput(1)\n",
    "\t\tcounter -= 1\n",
    "\t\tf_points.append([x[0][0], x[0][1]])\n",
    "\t\tplt.scatter(x[0][0], x[0][1])\n",
    "\t\tplt.draw()\n",
    "\t\tprint(\"Clicked point at \", x, \" | Clicks left: \", counter)\n",
    "\tplt.show()\n",
    "\tnp.savetxt('shape.dat', f_points)\n",
    "\treturn f_points\n",
    "\n",
    "# For selection of the second image - borrowed from Piazza with a few modifications\n",
    "def drag_control_points(img, cpts):\n",
    "    cpts = cpts.copy()\n",
    "    scale = (img.shape[0]**2 + img.shape[1]**2)**0.5/20\n",
    "    fh = plt.figure('Close window to terminate')\n",
    "    ah = fh.add_subplot(111)\n",
    "    ah.imshow(img, cmap='gray')\n",
    "    temp = ah.axis()\n",
    "    ah.set_xlim(temp[0:2])\n",
    "    ah.set_ylim(temp[2:4])\n",
    "    lh = [None]\n",
    "    lh[0] = ah.plot(cpts[:,0], cpts[:,1], 'g.')[0]\n",
    "\n",
    "    idx = [None]\n",
    "    figure_exist = [True]\n",
    "\n",
    "    def on_press(event):\n",
    "        diff = np.abs(np.array([[event.xdata, event.ydata]]) - cpts).sum(axis=(1,))\n",
    "        idx[0] = np.argmin(diff)\n",
    "        if diff[idx[0]] > scale:\n",
    "            idx[0] = None\n",
    "        else:\n",
    "            temp_cpts = np.delete(cpts, idx[0], axis=0)\n",
    "            lh[0].remove()\n",
    "            lh[0] = ah.plot(temp_cpts[:,0], temp_cpts[:,1], 'g.')[0]\n",
    "            fh.canvas.draw()\n",
    "\n",
    "    def on_release(event):\n",
    "        if idx[0] != None:\n",
    "            cpts[idx[0], 0] = event.xdata\n",
    "            cpts[idx[0], 1] = event.ydata\n",
    "            lh[0].remove()\n",
    "            lh[0] = ah.plot(cpts[:,0], cpts[:,1], 'g.')[0]\n",
    "            fh.canvas.draw()\n",
    "\n",
    "    def handle_close(event):\n",
    "        figure_exist[0] = False\n",
    "\n",
    "    #fh.canvas.mpl_connect('close_event', handle_close)\n",
    "    #fh.canvas.mpl_connect('button_press_event', on_press)\n",
    "    #fh.canvas.mpl_connect('button_release_event', on_release)\n",
    "    #fh.show()\n",
    "    #while figure_exist[0]:\n",
    "    #    plt.waitforbuttonpress()\n",
    "    return cpts\n",
    "\n",
    "# Helper function to combine points from image 1 and image 2\n",
    "def combinePoints(pt1, pt2):\n",
    "\tsuper_array = []\n",
    "\tfor coor1, coor2 in zip(pt1, pt2):\n",
    "\t\tsuper_array.append([tuple(coor1), tuple(coor2.tolist())])\n",
    "\treturn super_array\n",
    "\n",
    "# Main Function Calls\n",
    "# averageFace(\"frontimages\")\n",
    "selectPoints(im_in, im_out)\n",
    "#selectPoints(sys.argv[1], sys.argv[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Face correspondance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "def generate_face_correspondences(theImage1, theImage2):\n",
    "    # Detect the points of face.\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(r'C:\\Users\\Dell\\GitHub\\Fractal_Visuals\\shape_predictor_68_face_landmarks.dat')\n",
    "    corresp = np.zeros((68,2))\n",
    "\n",
    "    #imgList = crop_image(theImage1,theImage2)\n",
    "    imgList = [theImage1, theImage2]\n",
    "    list1 = []\n",
    "    list2 = []\n",
    "    j = 1\n",
    "\n",
    "    for img in imgList:\n",
    "\n",
    "        size = (img.shape[0],img.shape[1])\n",
    "        if(j == 1):\n",
    "            currList = list1\n",
    "        else:\n",
    "            currList = list2\n",
    "\n",
    "        # Ask the detector to find the bounding boxes of each face. The 1 in the\n",
    "        # second argument indicates that we should upsample the image 1 time. This\n",
    "        # will make everything bigger and allow us to detect more faces.\n",
    "        print(img)\n",
    "        dets = detector(img, 1)\n",
    "        print(dets)\n",
    "        try:\n",
    "            if len(dets) == 0:\n",
    "                raise NoFaceFound\n",
    "        except NoFaceFound:\n",
    "            print(\"Sorry, but I couldn't find a face in the image.\")\n",
    "\n",
    "        j=j+1\n",
    "\n",
    "        for k, rect in enumerate(dets):\n",
    "            \n",
    "            # Get the landmarks/parts for the face in rect.\n",
    "            shape = predictor(img, rect)\n",
    "            # corresp = face_utils.shape_to_np(shape)\n",
    "            \n",
    "            for i in range(0,68):\n",
    "                x = shape.part(i).x\n",
    "                y = shape.part(i).y\n",
    "                currList.append((x, y))\n",
    "                corresp[i][0] += x\n",
    "                corresp[i][1] += y\n",
    "                # cv2.circle(img, (x, y), 2, (0, 255, 0), 2)\n",
    "\n",
    "            # Add back the background\n",
    "            currList.append((1,1))\n",
    "            currList.append((size[1]-1,1))\n",
    "            currList.append(((size[1]-1)//2,1))\n",
    "            currList.append((1,size[0]-1))\n",
    "            currList.append((1,(size[0]-1)//2))\n",
    "            currList.append(((size[1]-1)//2,size[0]-1))\n",
    "            currList.append((size[1]-1,size[0]-1))\n",
    "            currList.append(((size[1]-1)//2,(size[0]-1)//2))\n",
    "\n",
    "        cv2.imwrite(\"test.png\", img)\n",
    "\n",
    "    # Add back the background\n",
    "    narray = corresp/2\n",
    "    narray = np.append(narray,[[1,1]],axis=0)\n",
    "    narray = np.append(narray,[[size[1]-1,1]],axis=0)\n",
    "    narray = np.append(narray,[[(size[1]-1)//2,1]],axis=0)\n",
    "    narray = np.append(narray,[[1,size[0]-1]],axis=0)\n",
    "    narray = np.append(narray,[[1,(size[0]-1)//2]],axis=0)\n",
    "    narray = np.append(narray,[[(size[1]-1)//2,size[0]-1]],axis=0)\n",
    "    narray = np.append(narray,[[size[1]-1,size[0]-1]],axis=0)\n",
    "    narray = np.append(narray,[[(size[1]-1)//2,(size[0]-1)//2]],axis=0)\n",
    "    \n",
    "    return [size,imgList[0],imgList[1],list1,list2,narray]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
